{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2ab69d8",
   "metadata": {},
   "source": [
    "# Neural Network Quantum States\n",
    "\n",
    "Neural network quantum states (NQS) represent a powerful approach to the quantum many-body problem, leveraging the universal approximation capabilities of neural networks to parametrize complex wavefunctions. In this framework, a neural network encodes the wavefunction amplitude $\\psi_\\theta(\\mathbf{x})$ for quantum configurations $\\mathbf{x}$, with network parameters $\\theta$ optimized via variational Monte Carlo methods.\n",
    "\n",
    "### Key Advantages\n",
    "\n",
    "- **Expressive power**: Neural networks can efficiently represent highly entangled quantum states that would be intractable for traditional variational ansätze\n",
    "- **Systematic improvability**: Network capacity can be increased systematically by adding layers or units to achieve desired accuracy\n",
    "- **Flexibility**: The approach is agnostic to system dimensionality, lattice geometry, and Hamiltonian structure\n",
    "- **Scalability**: Modern automatic differentiation and GPU acceleration enable application to systems with hundreds of particles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbf431b",
   "metadata": {},
   "source": [
    "## Theory: Variational Monte Carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc16511",
   "metadata": {},
   "source": [
    "The variational Monte Carlo (VMC) method provides a framework for finding approximate ground states by minimizing the energy functional\n",
    "$$E[\\psi] = \\frac{\\langle \\psi | H | \\psi \\rangle}{\\langle \\psi | \\psi \\rangle}$$\n",
    "over a parametrized family of wavefunctions $\\psi_\\theta$. For a given configuration $\\mathbf{x}$, we define the local energy as \n",
    "$$E_\\text{loc}(\\mathbf{x}) = \\sum_{\\mathbf{x}'} H_{\\mathbf{x}\\mathbf{x}'} \\frac{\\psi_\\theta(\\mathbf{x}')}{\\psi_\\theta(\\mathbf{x})} \\; ,$$\n",
    "which allows us to express the energy expectation value as\n",
    "$$E(\\theta) = \\frac{\\sum_{\\mathbf{x}} |\\psi_\\theta(\\mathbf{x})|^2 E_\\text{loc}(\\mathbf{x})}{\\sum_{\\mathbf{x}} |\\psi_\\theta(\\mathbf{x})|^2} \\; .$$\n",
    "This formulation is exact but intractable for large systems due to the exponential sum over configurations. Monte Carlo sampling resolves this issue by drawing configurations $\\mathbf{x}$ from the probability distribution\n",
    "$$ p_\\theta (\\mathbf{x}) = \\frac{|\\psi_\\theta(\\mathbf{x})|^2}{ \\sum_{\\mathbf{x}} | \\psi_\\theta(\\mathbf{x})|^2} \\; ,$$\n",
    "The energy then becomes\n",
    "$$E(\\theta) = \\mathbb{E}_{\\mathbf{x} \\sim p_\\theta}[E_\\text{loc}(\\mathbf{x})] \\; ,$$\n",
    "which we estimate via Monte Carlo as $E(\\theta) \\approx \\frac{1}{N} \\sum_{i=1}^N E_\\text{loc}(\\mathbf{x}_i)$ with $\\mathbf{x}_i \\sim p_\\theta$. Metropolis-Hastings or other MCMC algorithms generate these samples efficiently without computing the norm explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef433f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c717ae3b",
   "metadata": {},
   "source": [
    "## The VMC gradient expression\n",
    "\n",
    "The gradient of the energy expectation value with respect to the parameters, $\\nabla_\\theta E(\\theta)$ is a key quantity to optimize the total energy. It can be expressed in terms of the local energy and the logarithmic derivatives of the wavefunction. The expression is given by\n",
    "$$ \\frac{\\partial E}{\\partial \\theta ^\\mu} = 2 \\text{Re} \\; \\mathbb{E}_{\\mathbf{x} \\sim |\\psi _\\theta|^2 } \\left[ \\mathcal{O} ^* _\\mu (\\mathbf{x}) \\left( E_\\text{loc} (x) - E \\right) \\right] $$\n",
    "\n",
    "where $\\mathcal{O}_\\mu (\\mathbf{x}) = \\frac{\\partial}{\\partial \\theta^\\mu} \\ln \\psi_\\theta(\\mathbf{x})$ are the logarithmic derivatives of the wavefunction with respect to the parameters. This expression allows us to compute the gradient using samples drawn from the probability distribution $p_\\theta(\\mathbf{x})$, enabling efficient optimization of the neural network parameters via stochastic gradient descent or other optimization algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34c0b56",
   "metadata": {},
   "source": [
    "### Excercise: Derive this expression by direct differentiation of the energy expectation value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba183c6d",
   "metadata": {},
   "source": [
    "## Common Architectures\n",
    "Several neural network architectures have been successfully employed as NQS ansätze:\n",
    "- **Restricted Boltzmann Machines (RBM)**: Early NQS models used RBMs to capture correlations via hidden units, demonstrating success on spin systems.\n",
    "- **Feedforward Neural Networks**: Fully connected networks with nonlinear activations provide flexible function approximators for wavefunctions.\n",
    "- **Convolutional Neural Networks (CNNs)**: CNNs exploit spatial locality and translational symmetry, making them well-suited for lattice models.\n",
    "- **Recurrent Neural Networks (RNNs)**: RNNs capture sequential correlations, useful for one-dimensional systems.\n",
    "- **Transformer Networks**: Attention-based models that can capture long-range correlations effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c620f9a6",
   "metadata": {},
   "source": [
    "### Restricted Boltzmann Machines\n",
    "\n",
    "A Restricted Boltzmann Machine (RBM) is a generative stochastic neural network that can learn a **probability** distribution over its set of inputs. We think of it as a classical Boltzmann distribution defined on a bipartite graph of spins $s_i \\in \\{-1, 1\\}$. We think of it as \"physical\" spins coupled to some \"hidden\" spins $h_j \\in \\{-1, 1\\}$ that mediate correlations. The joint probability distribution is given by\n",
    "\n",
    "$$ p(\\mathbf{s}, \\mathbf{h}) \\propto \\exp \\left\\{ \\sum_i a_i s_i + \\sum_j b_j h_j + \\sum_{i,j} W_{ij} s_i h_j \\right\\} $$\n",
    "\n",
    "where $\\mathbf{s}$ are the visible units (spin configurations), $\\mathbf{h}$ are the hidden units, $a_i$ and $b_j$ are biases, $W_{ij}$ are weights connecting visible and hidden units. To get the probability of a visible configuration, we need marginalize over the hidden units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9091c09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18b650c8",
   "metadata": {},
   "source": [
    "## Excercise: The RBM state\n",
    "\n",
    "Show that the expression for the RBM probability $p(\\mathbf{s})$ after marginalizing over the hidden units is\n",
    "$$ p(\\mathbf{s}) = \\sum_{\\mathbf{h}} p(\\mathbf{s}, \\mathbf{h}) \\propto \\exp \\left\\{ \\sum_i a_i s_i \\right\\} \\times \\prod _k \\cosh \\left( \\sum_i W_{ik} s_i \\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8155113",
   "metadata": {},
   "source": [
    "The RBM wavefunction for a spin configuration $\\mathbf{s}$ is given by the same expression. The only trick is that we need the wavefunction amplitude, not the probability. This is achieved by making the parameters complex-valued and pretending the RBM defines the wavefunction (\"square root\" of the underlying probability distribution) directly.\n",
    "\n",
    "$$ \\ln \\psi (\\mathbf{s}) =  \\sum_i a_i s_i + \\sum_k \\ln \\cosh \\left( \\sum_i W_{ik} s_i \\right) $$\n",
    "\n",
    "Implement the RBM wavefunction in JAX using the provided scaffolding. Be extra careful with the $\\ln \\cosh (\\cdot)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d23d9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "from jaxtyping import Array, Float, Scalar, PyTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88384c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember -- JAX knows how to propagate through standard Python containers.\n",
    "\n",
    "from typing import NamedTuple\n",
    "\n",
    "class RBMParams(NamedTuple):\n",
    "    a: Float[Array, \"n_visible\"]           # Visible biases\n",
    "    b: Float[Array, \"n_hidden\"]            # Hidden biases\n",
    "    W: Float[Array, \"n_visible n_hidden\"]  # Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24ff0c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_rbm(params: RBMParams, s: Float[Array, \"n_visible\"]) -> Scalar:\n",
    "    pass # Your implementation here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a632bf25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a357ca5",
   "metadata": {},
   "source": [
    "# Excercise: Transverse Field Ising Model\n",
    "\n",
    "Consider a Hamiltonian of the form:\n",
    "$$H = -J \\sum_{\\langle i,j \\rangle} \\sigma_i^z \\sigma_j^z - h \\sum_i \\sigma_i^x,$$\n",
    "where $\\sigma_i^z$ and $\\sigma_i^x$ are the Pauli operators acting on the $i$-th spin, and $J$ and $h$ are coupling constants. Write down the local energy expression needed for the Variational Monte Carlo optimization. Assume a 1D circular geometry (use periodic boundary conditions).\n",
    "\n",
    "Use the folowing JAX template to implement the local energy function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaa053bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83d0fdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfim_local_energy(\n",
    "    logpsi: Callable, params: PyTree, x: Float[Array, \"n_visible\"], h: Scalar, J: Scalar = 1.0\n",
    ") -> Scalar:\n",
    "    \"\"\"\n",
    "    Compute the local energy for the transverse field Ising model.\n",
    "\n",
    "    Parameters:\n",
    "    logpsi: function\n",
    "        The neural network wavefunction taking configurations x as input.\n",
    "    params: PyTree\n",
    "        The parameters of the neural network wavefunction.\n",
    "    x: array\n",
    "        The spin configuration (1D array of +1/-1).\n",
    "    h: float\n",
    "        Transverse field strength.\n",
    "    J: float\n",
    "        Coupling constant for the ZZ interaction.\n",
    "\n",
    "    Returns:\n",
    "    float\n",
    "        The local energy E_loc(x).\n",
    "    \"\"\"\n",
    "    pass\n",
    "    # Your implementation here\n",
    "    # Of course, feel free to make any auxiliary functions as needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cbc4a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfd5152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97d639c7",
   "metadata": {},
   "source": [
    "## The optimization loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7732960",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "SOLUTIONS_PATH = Path(\"..\").resolve() # Adjust as needed\n",
    "sys.path.append(str(SOLUTIONS_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8065f1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "\n",
    "from src.solutions import RBMParams, eval_rbm, tfim_local_energy, energy_value_and_grad\n",
    "from src.sampler import SpinSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfec1833",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_spins = 10\n",
    "h = 0.2\n",
    "learning_rate = 0.01\n",
    "n_iters = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f78a5894",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb0130a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = RBMParams.initialize(n_spins, n_hidden=2*n_spins, key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b3abfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = SpinSampler(dims=(10,), n_samples=128, n_chains=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2207e848",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, = jax.random.split(key, 1)\n",
    "samples = sampler(lambda x: eval_rbm(params, x), key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87c7a82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 128, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4226ba75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9fc701",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def step(params, key):\n",
    "\n",
    "    samples = sampler(lambda x: eval_rbm(params, x), key).reshape(-1, n_spins)\n",
    "    eloc_fn = lambda *args: tfim_local_energy(*args, h=h, J=1.0)\n",
    "    energy, grads = energy_value_and_grad(eloc_fn, eval_rbm, params, samples)\n",
    "\n",
    "    params_ = jax.tree_util.tree_map(\n",
    "        lambda p, g: p - learning_rate * g, params, grads\n",
    "    )\n",
    "\n",
    "    return energy, params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e4be22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85b56ba6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dot_general requires contracting dimensions to have the same shape, got (10,) and (128,).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_iters):\n\u001b[1;32m      5\u001b[0m     key_ \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mfold_in(key, i)\n\u001b[0;32m----> 6\u001b[0m     energy, params \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m perf_counter() \u001b[38;5;241m-\u001b[39m clock \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2.0\u001b[39m:\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Energy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00menergy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "    \u001b[0;31m[... skipping hidden 14 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[14], line 6\u001b[0m, in \u001b[0;36mstep\u001b[0;34m(params, key)\u001b[0m\n\u001b[1;32m      4\u001b[0m samples \u001b[38;5;241m=\u001b[39m sampler(\u001b[38;5;28;01mlambda\u001b[39;00m x: eval_rbm(params, x), key)\n\u001b[1;32m      5\u001b[0m eloc_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs: tfim_local_energy(\u001b[38;5;241m*\u001b[39margs, h\u001b[38;5;241m=\u001b[39mh, J\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m energy, grads \u001b[38;5;241m=\u001b[39m \u001b[43menergy_value_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43meloc_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_rbm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m params_ \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mtree_util\u001b[38;5;241m.\u001b[39mtree_map(\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m p, g: p \u001b[38;5;241m-\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m g, params, grads\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m energy, params_\n",
      "File \u001b[0;32m~/Documents/Workshops & Talks/CCQ-GS-Workshop-2025/ccq-gs-workshop-vmc/src/solutions.py:90\u001b[0m, in \u001b[0;36menergy_value_and_grad\u001b[0;34m(eloc, logpsi, params, samples)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21menergy_value_and_grad\u001b[39m(\n\u001b[1;32m     76\u001b[0m     eloc: Callable, logpsi: Callable, params: PyTree, samples: Float[Array, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples ...\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     77\u001b[0m ):\n\u001b[1;32m     78\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the gradient of the energy expectation value.\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \n\u001b[1;32m     80\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m        Gradient of the energy expectation value with respect to parameters.\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m     O \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogpsi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m     local_energies \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: eloc(logpsi, params, x))(samples)\n\u001b[1;32m     92\u001b[0m     energy \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mmean(local_energies)\n",
      "    \u001b[0;31m[... skipping hidden 25 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Documents/Workshops & Talks/CCQ-GS-Workshop-2025/ccq-gs-workshop-vmc/src/solutions.py:35\u001b[0m, in \u001b[0;36meval_rbm\u001b[0;34m(params, s)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21meval_rbm\u001b[39m(params: RBMParams, s: Float[Array, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_visible\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Scalar:\n\u001b[1;32m     34\u001b[0m     a, b, W \u001b[38;5;241m=\u001b[39m params\n\u001b[0;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m \u001b[38;5;241m+\u001b[39m log_cosh(b \u001b[38;5;241m+\u001b[39m W\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m s)\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[0;32m~/Documents/Workshops & Talks/CCQ-GS-Workshop-2025/venv/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:1083\u001b[0m, in \u001b[0;36m_forward_operator_to_aval.<locals>.op\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mop\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m-> 1083\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Workshops & Talks/CCQ-GS-Workshop-2025/venv/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:583\u001b[0m, in \u001b[0;36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    581\u001b[0m args \u001b[38;5;241m=\u001b[39m (other, \u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m swap \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mself\u001b[39m, other)\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[0;32m--> 583\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;66;03m# Note: don't use isinstance here, because we don't want to raise for\u001b[39;00m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;66;03m# subclasses, e.g. NamedTuple objects that may override operators.\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(other) \u001b[38;5;129;01min\u001b[39;00m _rejected_binop_types:\n",
      "    \u001b[0;31m[... skipping hidden 15 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Documents/Workshops & Talks/CCQ-GS-Workshop-2025/venv/lib/python3.10/site-packages/jax/_src/numpy/tensor_contractions.py:245\u001b[0m, in \u001b[0;36mmatmul\u001b[0;34m(a, b, precision, preferred_element_type)\u001b[0m\n\u001b[1;32m    243\u001b[0m a \u001b[38;5;241m=\u001b[39m lax\u001b[38;5;241m.\u001b[39msqueeze(a, \u001b[38;5;28mtuple\u001b[39m(a_squeeze))\n\u001b[1;32m    244\u001b[0m b \u001b[38;5;241m=\u001b[39m lax\u001b[38;5;241m.\u001b[39msqueeze(b, \u001b[38;5;28mtuple\u001b[39m(b_squeeze))\n\u001b[0;32m--> 245\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mlax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot_general\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m  \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb_is_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_batch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m  \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_element_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreferred_element_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m result \u001b[38;5;241m=\u001b[39m lax\u001b[38;5;241m.\u001b[39mtranspose(out, perm)\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lax_internal\u001b[38;5;241m.\u001b[39m_convert_element_type(result, preferred_element_type, output_weak_type)\n",
      "    \u001b[0;31m[... skipping hidden 9 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Documents/Workshops & Talks/CCQ-GS-Workshop-2025/venv/lib/python3.10/site-packages/jax/_src/lax/lax.py:5216\u001b[0m, in \u001b[0;36m_dot_general_shape_rule\u001b[0;34m(lhs, rhs, dimension_numbers, precision, preferred_element_type, out_sharding)\u001b[0m\n\u001b[1;32m   5213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m core\u001b[38;5;241m.\u001b[39mdefinitely_equal_shape(lhs_contracting_shape, rhs_contracting_shape):\n\u001b[1;32m   5214\u001b[0m   msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdot_general requires contracting dimensions to have the same \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5215\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 5216\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(lhs_contracting_shape, rhs_contracting_shape))\n\u001b[1;32m   5218\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _dot_general_shape_computation(lhs\u001b[38;5;241m.\u001b[39mshape, rhs\u001b[38;5;241m.\u001b[39mshape, dimension_numbers)\n",
      "\u001b[0;31mTypeError\u001b[0m: dot_general requires contracting dimensions to have the same shape, got (10,) and (128,)."
     ]
    }
   ],
   "source": [
    "clock = perf_counter()\n",
    "\n",
    "for i in range(n_iters):\n",
    "\n",
    "    key_ = jax.random.fold_in(key, i)\n",
    "    energy, params = step(params, key_)\n",
    "\n",
    "    if perf_counter() - clock > 2.0:\n",
    "        print(f\"Iteration {i}, Energy: {energy:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0d378b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
